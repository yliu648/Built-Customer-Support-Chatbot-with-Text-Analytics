{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "import time\n",
    "import jieba\n",
    "import codecs\n",
    "import gc\n",
    "import tqdm\n",
    "import gensim\n",
    "from gensim import corpora, models, similarities\n",
    "import pyLDAvis.gensim\n",
    "from collections import defaultdict\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate class for segmentation\n",
    "class Seg(object):\n",
    "#     stopword_filepath = \"stopword.txt\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.stopwords = set()\n",
    "#         self.read_in_stopword()\n",
    "\n",
    "    def read_in_stopword(self):\n",
    "        file_obj = codecs.open(self.stopword_filepath, 'r', 'utf-8')\n",
    "        while True:\n",
    "            line = file_obj.readline()\n",
    "            line=line.strip('\\r\\n')\n",
    "            if not line:\n",
    "                break\n",
    "            self.stopwords.add(line)\n",
    "        file_obj.close()\n",
    "\n",
    "    #tokenize, remove stop words, and stemming using Porter Stemmer  \n",
    "    def cut(self, sentence, stopword= False, stemming = True):\n",
    "        seg_list = nltk.word_tokenize(sentence)\n",
    "        results = []\n",
    "        if stopword:\n",
    "            for seg in seg_list:\n",
    "                if seg in self.stopwords:\n",
    "                    continue\n",
    "                if seg.isalpha():\n",
    "                    results.append(seg)\n",
    "        else:\n",
    "            results=[token for token in seg_list if token.isalpha()]\n",
    "        if stemming:\n",
    "            porter = nltk.PorterStemmer()\n",
    "            results=[porter.stem(token.lower()) for token in results]\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate class for sentences\n",
    "class Sentence(object):\n",
    "    def __init__(self, sentence, seg, id=0):\n",
    "        self.id = id\n",
    "        self.origin_sentence = sentence\n",
    "        self.cuted_sentence = self.cut(seg)\n",
    "\n",
    "    # sentence segmentation\n",
    "    def cut(self, seg):\n",
    "        return seg.cut(self.origin_sentence)\n",
    "\n",
    "    # get words after sentence segmentation\n",
    "    def get_cuted_sentence(self):\n",
    "        return self.cuted_sentence\n",
    "\n",
    "    def get_origin_sentence(self):\n",
    "        return self.origin_sentence\n",
    "\n",
    "    # set scores for sentences\n",
    "    def set_score(self, score):\n",
    "        self.score = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate class for calculating similarity\n",
    "class SentenceSimilarity():\n",
    "    def __init__(self, seg, csName):\n",
    "        self.seg = seg\n",
    "        self.csName = csName.lower()\n",
    "\n",
    "    def set_sentences(self, sentences):\n",
    "        self.sentences = []\n",
    "        for i in range(0, len(sentences)):\n",
    "            self.sentences.append(Sentence(sentences[i], self.seg, i))\n",
    "\n",
    "    # get words after sentence segmentation\n",
    "    def get_cuted_sentences(self):\n",
    "        cuted_sentences = []\n",
    "        for sentence in self.sentences:\n",
    "            cuted_sentences.append(sentence.get_cuted_sentence())\n",
    "        return cuted_sentences\n",
    "\n",
    "    # using basic model to build complicated models\n",
    "    def simple_model(self, min_frequency = 1):\n",
    "        self.texts = self.get_cuted_sentences()\n",
    "\n",
    "        # remove words with lowest frequency\n",
    "        frequency = defaultdict(int)\n",
    "        for text in self.texts:\n",
    "            for token in text:\n",
    "                frequency[token] += 1        \n",
    "        self.texts = [[token for token in text if (frequency[token] > min_frequency) and (token != self.csName)] for text in self.texts]\n",
    "        # generate dictionary class\n",
    "        self.dictionary = corpora.Dictionary(self.texts)\n",
    "        # build a corpus\n",
    "        self.corpus_simple = [self.dictionary.doc2bow(text) for text in self.texts]\n",
    "    \n",
    "    def average_word_vectors(self,words, model, vocabulary, num_features):    \n",
    "        feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
    "        nwords = 0.\n",
    "        for word in words:\n",
    "            if word in vocabulary: \n",
    "                nwords = nwords + 1.\n",
    "                feature_vector = np.add(feature_vector, model[word])\n",
    "        if nwords:\n",
    "            feature_vector = np.divide(feature_vector, nwords)\n",
    "        return feature_vector \n",
    "   \n",
    "    # averaged word vector features \n",
    "    def averaged_word_vectorizer(self,corpus, model, num_features):\n",
    "        vocabulary = set(model.wv.index2word)\n",
    "        if type(corpus[0])==list:\n",
    "            features = [self.average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
    "                            for tokenized_sentence in corpus]\n",
    "        else:\n",
    "            features=self.average_word_vectors(corpus, model, vocabulary, num_features)\n",
    "        return np.array(features)\n",
    "        \n",
    "    # build word2vec model      \n",
    "    def w2vModel(self):\n",
    "        self.simple_model()\n",
    "        # switch from simple model to comprehensive\n",
    "        self.model = models.Word2Vec(self.texts,size=200, min_count=5)\n",
    "        self.features = self.averaged_word_vectorizer(corpus=self.texts,\n",
    "                                                 model=self.model,\n",
    "                                                 num_features=200)           \n",
    "    # build tfidf model\n",
    "    def TfidfModel(self):\n",
    "        self.simple_model()\n",
    "        # switch from simple model to comprehensive\n",
    "        self.model = models.TfidfModel(self.corpus_simple)\n",
    "        self.corpus = self.model[self.corpus_simple]\n",
    "        # Generate Similarity Matrix for TFIDF model\n",
    "        self.index = similarities.MatrixSimilarity(self.corpus)\n",
    "\n",
    "    # lsi model\n",
    "    def LsiModel(self):\n",
    "        self.simple_model()\n",
    "        # switch from simple model to comprehensive\n",
    "        self.model = models.LsiModel(self.corpus_simple)\n",
    "        self.corpus = self.model[self.corpus_simple]\n",
    "        # Generate Similarity Matrix for LSI model\n",
    "        self.index = similarities.MatrixSimilarity(self.corpus)\n",
    "\n",
    "    # lda model\n",
    "    def LdaModel(self):\n",
    "        self.simple_model()\n",
    "        # switch from simple model to comprehensive\n",
    "        self.model = models.LdaModel(self.corpus_simple)\n",
    "        self.corpus = self.model[self.corpus_simple]\n",
    "        # Generate Similarity Matrix for LDA model\n",
    "        self.index = similarities.MatrixSimilarity(self.corpus)\n",
    "\n",
    "    # preliminary steps for input sentences\n",
    "    def sentence2vec(self, sentence):\n",
    "        sentence = Sentence(sentence, self.seg).get_cuted_sentence()\n",
    "        vec_bow = self.dictionary.doc2bow(sentence)\n",
    "        return self.model[vec_bow]\n",
    "    \n",
    "    def bow2vec(self):\n",
    "        vec = []\n",
    "        length = max(self.dictionary) + 1\n",
    "        for content in self.corpus:\n",
    "            sentence_vectors = np.zeros(length)\n",
    "            for co in content:\n",
    "                sentence_vectors[co[0]] = co[1]  # 将句子出现的单词的tf-idf表示放入矩阵中\n",
    "            vec.append(sentence_vectors)\n",
    "        return vec\n",
    "\n",
    "    # look for the most similar sentences\n",
    "    # input: test sentence    \n",
    "    def cosine_similarity(self,x,y):\n",
    "        num = x.dot(y.T)\n",
    "        denom = np.linalg.norm(x) * np.linalg.norm(y)\n",
    "        return num / denom\n",
    "    \n",
    "    def similarity_k(self, sentence, k):        \n",
    "        sentence_vec = self.sentence2vec(sentence)\n",
    "        sims = self.index[sentence_vec]\n",
    "        sim_k = sorted(enumerate(sims), key=lambda item: item[1], reverse=True)[:k]\n",
    "        indexs = [i[0] for i in sim_k]\n",
    "        scores = [i[1] for i in sim_k]\n",
    "        return indexs, scores\n",
    "    \n",
    "    def similarity_v(self, sentence, k):       \n",
    "        cuts=Sentence(sentence, self.seg).get_cuted_sentence()\n",
    "        sentence_vec=self.averaged_word_vectorizer(corpus=cuts,\n",
    "                                      model=self.model,\n",
    "                                     num_features=200)\n",
    "        d=[]\n",
    "        for i in range(len(self.features)):\n",
    "            score=self.cosine_similarity(self.features[i],sentence_vec)\n",
    "            if score >=0 or score <=0:\n",
    "                d.append([i,score]) \n",
    "        sim_k = sorted(d, key=lambda item: item[1], reverse=True)[:k]\n",
    "        indexs = [i[0] for i in sim_k]\n",
    "        scores = [i[1] for i in sim_k]\n",
    "        return indexs, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(df,seg):\n",
    "    qList = []\n",
    "    # list of keywords in tweets\n",
    "    qList_kw = []\n",
    "    aList = []\n",
    "    data = df[['text_y','text_x']]\n",
    "    data_ls = np.array(data).tolist()\n",
    "    for t in data_ls:\n",
    "        qList.append(t[0])\n",
    "        qList_kw.append(seg.cut(t[0]))\n",
    "        aList.append(t[1])\n",
    "    return qList_kw, qList, aList\n",
    "\n",
    "# define function for frequency distribution plot\n",
    "def plot_words(wordList):\n",
    "    fDist = FreqDist(wordList)\n",
    "    #print(fDist.most_common())\n",
    "    print(\"Total number of words: \",fDist.N())\n",
    "    print(\"Total number of distinct words: \",fDist.B())\n",
    "    fDist.plot(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data and take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df=pd.read_csv('C:/Users/yongl/Fordham/Spring 2020/Text Analytics/Text project/customer-support-on-twitter/twcs/twcs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id   author_id  inbound                      created_at  \\\n",
       "0         1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n",
       "1         2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n",
       "2         3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n",
       "3         4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n",
       "4         5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0  @115712 I understand. I would like to assist y...                 2   \n",
       "1      @sprintcare and how do you propose we do that               NaN   \n",
       "2  @sprintcare I have sent several private messag...                 1   \n",
       "3  @115712 Please send us a Private Message so th...                 3   \n",
       "4                                 @sprintcare I did.                 4   \n",
       "\n",
       "   in_response_to_tweet_id  \n",
       "0                      3.0  \n",
       "1                      1.0  \n",
       "2                      4.0  \n",
       "3                      5.0  \n",
       "4                      6.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preview data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AmazonHelp</th>\n",
       "      <td>169840</td>\n",
       "      <td>169840</td>\n",
       "      <td>169840</td>\n",
       "      <td>169840</td>\n",
       "      <td>85274</td>\n",
       "      <td>169287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AppleSupport</th>\n",
       "      <td>106860</td>\n",
       "      <td>106860</td>\n",
       "      <td>106860</td>\n",
       "      <td>106860</td>\n",
       "      <td>31564</td>\n",
       "      <td>106719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uber_Support</th>\n",
       "      <td>56270</td>\n",
       "      <td>56270</td>\n",
       "      <td>56270</td>\n",
       "      <td>56270</td>\n",
       "      <td>18036</td>\n",
       "      <td>56261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpotifyCares</th>\n",
       "      <td>43265</td>\n",
       "      <td>43265</td>\n",
       "      <td>43265</td>\n",
       "      <td>43265</td>\n",
       "      <td>13786</td>\n",
       "      <td>43243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delta</th>\n",
       "      <td>42253</td>\n",
       "      <td>42253</td>\n",
       "      <td>42253</td>\n",
       "      <td>42253</td>\n",
       "      <td>12014</td>\n",
       "      <td>42197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tesco</th>\n",
       "      <td>38573</td>\n",
       "      <td>38573</td>\n",
       "      <td>38573</td>\n",
       "      <td>38573</td>\n",
       "      <td>11148</td>\n",
       "      <td>38501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AmericanAir</th>\n",
       "      <td>36764</td>\n",
       "      <td>36764</td>\n",
       "      <td>36764</td>\n",
       "      <td>36764</td>\n",
       "      <td>14556</td>\n",
       "      <td>36598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TMobileHelp</th>\n",
       "      <td>34317</td>\n",
       "      <td>34317</td>\n",
       "      <td>34317</td>\n",
       "      <td>34317</td>\n",
       "      <td>9759</td>\n",
       "      <td>34287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comcastcares</th>\n",
       "      <td>33031</td>\n",
       "      <td>33031</td>\n",
       "      <td>33031</td>\n",
       "      <td>33031</td>\n",
       "      <td>7625</td>\n",
       "      <td>33007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>British_Airways</th>\n",
       "      <td>29361</td>\n",
       "      <td>29361</td>\n",
       "      <td>29361</td>\n",
       "      <td>29361</td>\n",
       "      <td>10099</td>\n",
       "      <td>29315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id  inbound  created_at    text  response_tweet_id  \\\n",
       "author_id                                                                   \n",
       "AmazonHelp         169840   169840      169840  169840              85274   \n",
       "AppleSupport       106860   106860      106860  106860              31564   \n",
       "Uber_Support        56270    56270       56270   56270              18036   \n",
       "SpotifyCares        43265    43265       43265   43265              13786   \n",
       "Delta               42253    42253       42253   42253              12014   \n",
       "Tesco               38573    38573       38573   38573              11148   \n",
       "AmericanAir         36764    36764       36764   36764              14556   \n",
       "TMobileHelp         34317    34317       34317   34317               9759   \n",
       "comcastcares        33031    33031       33031   33031               7625   \n",
       "British_Airways     29361    29361       29361   29361              10099   \n",
       "\n",
       "                 in_response_to_tweet_id  \n",
       "author_id                                 \n",
       "AmazonHelp                        169287  \n",
       "AppleSupport                      106719  \n",
       "Uber_Support                       56261  \n",
       "SpotifyCares                       43243  \n",
       "Delta                              42197  \n",
       "Tesco                              38501  \n",
       "AmericanAir                        36598  \n",
       "TMobileHelp                        34287  \n",
       "comcastcares                       33007  \n",
       "British_Airways                    29315  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort by companies responded the most\n",
    "df[df.inbound==False].groupby('author_id').count().sort_values('text',ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected the three most responsive companies\n",
    "clist=df[df.inbound==False].groupby('author_id').count().sort_values('text',ascending=False)[:3].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AmazonHelp', 'AppleSupport', 'Uber_Support']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join request and response into the same row: 'text_x' is the response from customer services; 'text_y' is the request\n",
    "def pre(df,author):\n",
    "    a=df[df.author_id==author]\n",
    "    a=a.merge(df.loc[:,['tweet_id','text']],left_on='in_response_to_tweet_id',right_on='tweet_id')\n",
    "    a=a[a.response_tweet_id.isnull()]    \n",
    "    a['text_x']=a.text_x.apply(lambda x: x[:x.find('@')]+x[x.find('@')+8:])    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[        tweet_id_x   author_id  inbound                      created_at  \\\n",
       " 2              275  AmazonHelp    False  Wed Nov 22 10:06:26 +0000 2017   \n",
       " 3              324  AmazonHelp    False  Wed Nov 22 09:06:00 +0000 2017   \n",
       " 6              620  AmazonHelp    False  Tue Oct 31 22:28:34 +0000 2017   \n",
       " 8              625  AmazonHelp    False  Tue Oct 31 22:34:32 +0000 2017   \n",
       " 10             629  AmazonHelp    False  Wed Nov 01 12:53:34 +0000 2017   \n",
       " ...            ...         ...      ...                             ...   \n",
       " 168818     2987819  AmazonHelp    False  Wed Nov 22 06:19:27 +0000 2017   \n",
       " 168819     2987821  AmazonHelp    False  Wed Nov 22 06:17:26 +0000 2017   \n",
       " 168820     2987900  AmazonHelp    False  Wed Nov 22 07:09:54 +0000 2017   \n",
       " 168821     2987902  AmazonHelp    False  Wed Nov 22 07:09:53 +0000 2017   \n",
       " 168822     2987938  AmazonHelp    False  Wed Nov 22 07:49:52 +0000 2017   \n",
       " \n",
       "                                                    text_x response_tweet_id  \\\n",
       " 2          恐れ入ります。至らない点も多々あるかとは存じますが、今後ともどうぞよろしくお願いします。ET               NaN   \n",
       " 3       ご不便をおかけしております。アプリをご利用でしょうか。強制停止&gt;端末の再起動にて改善す...               NaN   \n",
       " 6       I am unable to affect your account via Twitter...               NaN   \n",
       " 8            Wir haben zu danken. Schönen Abend noch. ^JS               NaN   \n",
       " 10                          Thanks for your patience. ^KM               NaN   \n",
       " ...                                                   ...               ...   \n",
       " 168818  ご心配をおかけしております。ご案内しているお届け予定日を経過しても未着の場合はカスタマーサー...               NaN   \n",
       " 168819  該当のメッセージは、https://t.co/st4oU5QbhPからお送りしたものではござ...               NaN   \n",
       " 168820  ご承知のとおり、残念ながら悪質な詐欺が増加しているようですのでお気を付けください。\\nhtt...               NaN   \n",
       " 168821  ¡Hola Crispín! Lamento mucho la confusión caus...               NaN   \n",
       " 168822  当サイトからそのようなメールをお送りすることはございません。当サイトの名をかたるフィッシング...               NaN   \n",
       " \n",
       "         in_response_to_tweet_id  tweet_id_y  \\\n",
       " 2                         274.0         274   \n",
       " 3                         325.0         325   \n",
       " 6                         621.0         621   \n",
       " 8                         623.0         623   \n",
       " 10                        627.0         627   \n",
       " ...                         ...         ...   \n",
       " 168818                2987820.0     2987820   \n",
       " 168819                2987822.0     2987822   \n",
       " 168820                2987901.0     2987901   \n",
       " 168821                2987903.0     2987903   \n",
       " 168822                2987939.0     2987939   \n",
       " \n",
       "                                                    text_y  \n",
       " 2                           @AmazonHelp こちらこそありがとうございました。  \n",
       " 3                                amazonプライムビデオ、再生エラーが多いです  \n",
       " 6       @115823 I want my amazon payments account CLOS...  \n",
       " 8                    @AmazonHelp Okay, danke für die Info  \n",
       " 10      @AmazonHelp @115826 Yeah this is crazy we’re l...  \n",
       " ...                                                   ...  \n",
       " 168818  Amazonで注文したDVDがまだ届かない･･･\\n昨日まで到着予定なんだけど問い合わせする...  \n",
       " 168819  たいへん！！Amazonでピンク動画見たら請求来た！！私の消息途絶えたらAmazonに社会か...  \n",
       " 168820  架空請求きたよww\\n\\nしかとショートメールでAmazon相談係。 https://t.c...  \n",
       " 168821  Señores de @116928 estoy confuso sobre el públ...  \n",
       " 168822  いきなり来たんだけど\\nなんですかこれ！！？\\n\\n@120465 https://t.co...  \n",
       " \n",
       " [84566 rows x 9 columns],\n",
       "         tweet_id_x     author_id  inbound                      created_at  \\\n",
       " 1              699  AppleSupport    False  Tue Oct 31 22:36:27 +0000 2017   \n",
       " 2              701  AppleSupport    False  Tue Oct 31 22:26:49 +0000 2017   \n",
       " 7              716  AppleSupport    False  Tue Oct 31 22:24:54 +0000 2017   \n",
       " 9              720  AppleSupport    False  Tue Oct 31 22:24:27 +0000 2017   \n",
       " 11             724  AppleSupport    False  Tue Oct 31 22:22:31 +0000 2017   \n",
       " ...            ...           ...      ...                             ...   \n",
       " 106642     2987481  AppleSupport    False  Wed Nov 22 00:51:00 +0000 2017   \n",
       " 106644     2987604  AppleSupport    False  Wed Nov 22 02:33:58 +0000 2017   \n",
       " 106645     2987606  AppleSupport    False  Wed Nov 22 02:29:26 +0000 2017   \n",
       " 106646     2987662  AppleSupport    False  Wed Nov 22 03:27:30 +0000 2017   \n",
       " 106647     2987722  AppleSupport    False  Wed Nov 22 04:15:29 +0000 2017   \n",
       " \n",
       "                                                    text_x response_tweet_id  \\\n",
       " 1       Lets take a closer look into this issue. Selec...               NaN   \n",
       " 2       Let's go to DM for the next steps. DM us here:...               NaN   \n",
       " 7       We'd like to investigate further with you. Sen...               NaN   \n",
       " 9         We've received your DM and will continue there.               NaN   \n",
       " 11      Reach out to us via DM, and we can take a look...               NaN   \n",
       " ...                                                   ...               ...   \n",
       " 106642  Let's figure out why this is happening. To sta...               NaN   \n",
       " 106644  We're certainly glad to get you pointed in the...               NaN   \n",
       " 106645  We'd love to help! Which device are you using?...               NaN   \n",
       " 106646  We'd like to help. Send us a DM and we can sta...               NaN   \n",
       " 106647  We'd love to offer our help in making sure you...               NaN   \n",
       " \n",
       "         in_response_to_tweet_id  tweet_id_y  \\\n",
       " 1                         697.0         697   \n",
       " 2                         702.0         702   \n",
       " 7                         717.0         717   \n",
       " 9                         721.0         721   \n",
       " 11                        725.0         725   \n",
       " ...                         ...         ...   \n",
       " 106642                2987482.0     2987482   \n",
       " 106644                2987605.0     2987605   \n",
       " 106645                2987607.0     2987607   \n",
       " 106646                2987663.0     2987663   \n",
       " 106647                2987723.0     2987723   \n",
       " \n",
       "                                                    text_y  \n",
       " 1       @AppleSupport The newest update. I️ made sure ...  \n",
       " 2       @AppleSupport Tried resetting my settings .. r...  \n",
       " 7       @AppleSupport This is what is happening... htt...  \n",
       " 9       @AppleSupport are the call centres closed for ...  \n",
       " 11      @115861 @115862 @AppleSupport I️ upgraded. I️t...  \n",
       " ...                                                   ...  \n",
       " 106642  @AppleSupport why is my iPhone 7 constantly se...  \n",
       " 106644  Hey @AppleSupport - not being able to duplicat...  \n",
       " 106645  Yo @AppleSupport is that weird glitch w/ the c...  \n",
       " 106646  What the fuck @AppleSupport  my phone keeps ha...  \n",
       " 106647  Is anyone having #iphone issues with there pho...  \n",
       " \n",
       " [75296 rows x 9 columns],\n",
       "        tweet_id_x     author_id  inbound                      created_at  \\\n",
       " 1             770  Uber_Support    False  Tue Oct 31 22:31:08 +0000 2017   \n",
       " 2             772  Uber_Support    False  Tue Oct 31 22:25:26 +0000 2017   \n",
       " 3             774  Uber_Support    False  Tue Oct 31 22:19:18 +0000 2017   \n",
       " 4             776  Uber_Support    False  Tue Oct 31 22:17:58 +0000 2017   \n",
       " 7             783  Uber_Support    False  Tue Oct 31 22:15:25 +0000 2017   \n",
       " ...           ...           ...      ...                             ...   \n",
       " 56188     2987383  Uber_Support    False  Wed Nov 22 00:10:38 +0000 2017   \n",
       " 56189     2987608  Uber_Support    False  Wed Nov 22 02:32:31 +0000 2017   \n",
       " 56190     2987652  Uber_Support    False  Tue Oct 31 22:04:17 +0000 2017   \n",
       " 56191     2987654  Uber_Support    False  Tue Oct 31 22:01:58 +0000 2017   \n",
       " 56192     2987656  Uber_Support    False  Tue Oct 31 22:00:12 +0000 2017   \n",
       " \n",
       "                                                   text_x response_tweet_id  \\\n",
       " 1      We apologize for the trouble! Send us a DM wit...               NaN   \n",
       " 2      We're here to help! Send us a note here, https...               NaN   \n",
       " 3      We’re here to help, Travis! Send us a note via...               NaN   \n",
       " 4      For more info about UberEats availability clic...               NaN   \n",
       " 7      We're sorry to hear this was your experience, ...               NaN   \n",
       " ...                                                  ...               ...   \n",
       " 56188  We'll be happy to take a closer look. Send us ...               NaN   \n",
       " 56189  Here to help! Send us note via https://t.co/h8...               NaN   \n",
       " 56190  We can definitely take a look! Send us a DM wi...               NaN   \n",
       " 56191  Happy to follow up. Send us a note at https://...               NaN   \n",
       " 56192  Here to help! Send us a note via https://t.co/...               NaN   \n",
       " \n",
       "        in_response_to_tweet_id  tweet_id_y  \\\n",
       " 1                        768.0         768   \n",
       " 2                        773.0         773   \n",
       " 3                        775.0         775   \n",
       " 4                        777.0         777   \n",
       " 7                        784.0         784   \n",
       " ...                        ...         ...   \n",
       " 56188                2987384.0     2987384   \n",
       " 56189                2987609.0     2987609   \n",
       " 56190                2987653.0     2987653   \n",
       " 56191                2987655.0     2987655   \n",
       " 56192                2987657.0     2987657   \n",
       " \n",
       "                                                   text_y  \n",
       " 1      @115872 Happy to follow up! Contact us via htt...  \n",
       " 2      @115873 my driver just drove me to the departm...  \n",
       " 3      @Uber_Support I’m not getting your texts. http...  \n",
       " 4      @115877 got this threw my door today went to o...  \n",
       " 7      1 hour+ inside an old Altima that smells and h...  \n",
       " ...                                                  ...  \n",
       " 56188  @Uber_Support been 'onboarding' for a few days...  \n",
       " 56189  @Uber_Support i've got cancellation fee becaus...  \n",
       " 56190  @115873 one of yo9ur drivers has my iphone in ...  \n",
       " 56191  @115873 why do I have to have a credit when yo...  \n",
       " 56192  @115873 @Uber_Support get it together. There's...  \n",
       " \n",
       " [38234 rows x 9 columns]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a list of tweets responded by 'AmazonHelp', 'AppleSupport', and 'Uber_Support'\n",
    "dataset=[]\n",
    "for i in clist:\n",
    "    dataset.append(pre(df,i))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a model for encoding: w2v, tfidf, lsi, or lda? LDA\n",
      "Please input right\n",
      "Select a model for encoding: w2v, tfidf, lsi, or lda? lda\n",
      "Please wait for system to set up\n",
      "Finished! Time cost for setting up: 671.035742521286 s\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Hey there! This is Auto Customer Service. First please choose the company:\n",
      "0 for Amazon, 1 for Apple, 2 for Uber: 0\n",
      "Please type your question here ('q' to quit): I selected free two day delivery but the package arrived late\n",
      "Thanks for asking, here is the 1 most likely answer(s) from AmazonHelp\n",
      "Hi, you can leave your comments and submit additional feedback about packaging here: https://t.co/fxgZ6hTrFA.^MA\n",
      "Is this problem solved? (input y/n)n\n",
      "\n",
      "Thanks for asking, here is the 2 most likely answer(s) from AmazonHelp\n",
      "I'm so sorry for the delay. If you have a moment, please contact us by phone or chat here: : https://t.co/hApLpMlfHN. ^LH\n",
      "Is this problem solved? (input y/n)n\n",
      "\n",
      "Thanks for asking, here is the 3 most likely answer(s) from AmazonHelp\n",
      "I'm so sorry for the wait. If you have a moment, please contact us by chat or phone: https://t.co/JzP7hlA23B. ^LH\n",
      "Is this problem solved? (input y/n)n\n",
      "\n",
      "Thanks for asking, here is the 4 most likely answer(s) from AmazonHelp\n",
      "Please don’t provide your order details as we consider them to be personal info. Our page is visible to public. ^SG(2/2)\n",
      "Is this problem solved? (input y/n)n\n",
      "\n",
      "Thanks for asking, here is the 5 most likely answer(s) from AmazonHelp\n",
      "Hi there Morgan, sorry to hear about the delays. Are you currently waiting on an order? When was the delivery date? ^SA\n",
      "Is this problem solved? (input y/n)y\n",
      "\n",
      "Thank you for using Auto Customer Service. It's my pleasure to solve your problem.\n",
      "Similar questions： @115830 im happy my free '5 day' delivery came next day but did i order extra cardboard with my ram? This is extreme packaging... https://t.co/NaFYA17IXL,                score： 0.7357646226882935\n",
      "Similar questions： @115821 paid for next day delivery.. had it confirmed and alas, no package #nothappy,                score： 0.7357333898544312\n",
      "Similar questions： @115821 paid for next day delivery.. had it confirmed and alas, no package #nothappy,                score： 0.7356058955192566\n",
      "Similar questions： #AmazonIndia\n",
      "Pathetic Service for Order ID 406-8312991-4366749.\n",
      "Paid extra for guranteed next day delivery but no one came for delivery.,                score： 0.7345274090766907\n",
      "Similar questions： @115830 what’s the point of #AmazonPrime when half the time you miss promised delivery dates?!,                score： 0.7344967722892761\n",
      "It took 0.0857701301574707 s to look for the answers\n",
      "---------------------------------------------------------------------------------------------------\n",
      "What else can I help\n",
      "Please type your question here ('q' to quit): I selected free two day delivery but the package arrived late\n",
      "Thanks for asking, here is the 1 most likely answer(s) from AmazonHelp\n",
      "Hi, you can leave your comments and submit additional feedback about packaging here: https://t.co/fxgZ6hTrFA.^MA\n",
      "Is this problem solved? (input y/n)n\n",
      "\n",
      "Thanks for asking, here is the 2 most likely answer(s) from AmazonHelp\n",
      "I'm so sorry for the delay. If you have a moment, please contact us by phone or chat here: : https://t.co/hApLpMlfHN. ^LH\n",
      "Is this problem solved? (input y/n)n\n",
      "\n",
      "Thanks for asking, here is the 3 most likely answer(s) from AmazonHelp\n",
      "I'm so sorry for the wait. If you have a moment, please contact us by chat or phone: https://t.co/JzP7hlA23B. ^LH\n",
      "Is this problem solved? (input y/n)n\n",
      "\n",
      "Thanks for asking, here is the 4 most likely answer(s) from AmazonHelp\n",
      "Please don’t provide your order details as we consider them to be personal info. Our page is visible to public. ^SG(2/2)\n",
      "Is this problem solved? (input y/n)n\n",
      "\n",
      "Thanks for asking, here is the 5 most likely answer(s) from AmazonHelp\n",
      "I'm sorry about the situation. Kindly share your details here: https://t.co/GIJyeYqKE0 and I'll look into this. ^SG(1/2)\n",
      "Is this problem solved? (input y/n)n\n",
      "\n",
      "Similar questions： @115830 im happy my free '5 day' delivery came next day but did i order extra cardboard with my ram? This is extreme packaging... https://t.co/NaFYA17IXL,                score： 0.7358694672584534\n",
      "Similar questions： @115821 paid for next day delivery.. had it confirmed and alas, no package #nothappy,                score： 0.7354776859283447\n",
      "Similar questions： @115821 paid for next day delivery.. had it confirmed and alas, no package #nothappy,                score： 0.7353527545928955\n",
      "Similar questions： #AmazonIndia\n",
      "Pathetic Service for Order ID 406-8312991-4366749.\n",
      "Paid extra for guranteed next day delivery but no one came for delivery.,                score： 0.7343747615814209\n",
      "Similar questions： #AmazonIndia\n",
      "Pathetic Service for Order ID 406-8312991-4366749.\n",
      "Paid extra for guranteed next day delivery but no one came for delivery.,                score： 0.7341427803039551\n",
      "It took 0.06981253623962402 s to look for the answers\n",
      "---------------------------------------------------------------------------------------------------\n",
      "What else can I help\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    way=input('Select a model for encoding: w2v, tfidf, lsi, or lda? ')\n",
    "    #Set up for specific model\n",
    "    w2v=False\n",
    "    if way == 'w2v':\n",
    "        w2v=True\n",
    "        print('Please wait for the system to set up.')\n",
    "        time1=time.time()\n",
    "        seg0 = Seg()\n",
    "        List_kw0, questionList0, answerList0 = read_corpus(dataset[0],seg0)\n",
    "        ss0 = SentenceSimilarity(seg0,clist[0])\n",
    "        ss0.set_sentences(questionList0)\n",
    "        ss0.w2vModel()\n",
    "#         ss0.TfidfModel() \n",
    "        #     ss.LsiModel()\n",
    "        #     ss.LdaModel()        \n",
    "        seg1 = Seg()\n",
    "        List_kw1, questionList1, answerList1 = read_corpus(dataset[1],seg1)\n",
    "        ss1 = SentenceSimilarity(seg1,clist[1])\n",
    "        ss1.set_sentences(questionList1)\n",
    "        ss1.w2vModel()\n",
    "#         ss1.TfidfModel() \n",
    "        seg2 = Seg()\n",
    "        List_kw2, questionList2, answerList2 = read_corpus(dataset[2],seg2)\n",
    "        ss2 = SentenceSimilarity(seg2,clist[2])\n",
    "        ss2.set_sentences(questionList2)\n",
    "        ss2.w2vModel()\n",
    "#         ss2.TfidfModel() \n",
    "        time2=time.time()\n",
    "        print('The setup is now complete, which took {} s.'.format(time2-time1))\n",
    "        print('---------------------------------------------------------------------------------------------------')\n",
    "        \n",
    "        #Start chatting with customer\n",
    "        print('Hey there! This is Auto Customer Service. First, please choose the company you would like to chat with:')\n",
    "        while True:\n",
    "            company=input(\"0 for Amazon, 1 for Apple, 2 for Uber, 'q' to quit: \")\n",
    "            if company in ['0','1','2']:\n",
    "                while True:\n",
    "                    question = input(\"Please type your question here or press 'q' to quit: \")\n",
    "                    if question == 'q':\n",
    "                        break\n",
    "                    time1 = time.time()\n",
    "\n",
    "                    # chats for Amazon\n",
    "                    if company=='0':\n",
    "                        question_k = ss0.similarity_v(question, 5)\n",
    "                        time2 = time.time()\n",
    "                        for i in range(5):\n",
    "                            if question_k[1][i]>=0.5:\n",
    "                                print('Thanks for asking, here is the',i+1,'most likely answer(s) from AmazonHelp:')\n",
    "                                print(answerList0[question_k[0][i]])\n",
    "                                while True:\n",
    "                                    solved=input('Is your problem solved? (input y/n)')\n",
    "                                    if solved=='n' or solved=='y':\n",
    "                                        print()\n",
    "                                        break\n",
    "                                    elif solved!='y':\n",
    "                                        input('Please enter y/n')\n",
    "                                        continue\n",
    "                                if solved=='y':\n",
    "                                    print('Thank you for using Auto Customer Service. It\\'s my pleasure to help.')\n",
    "                                    break\n",
    "\n",
    "                            else:\n",
    "                                if i == 0:\n",
    "                                    print('Unfortunately, I can\\'t find any answer in our database system, please contact human services.' )\n",
    "                                else:\n",
    "                                    print('Unfortunately, I can\\'t find more answers in the system, please contact human services if you still have questions.')\n",
    "                                break\n",
    "\n",
    "\n",
    "                        for idx, score in zip(*question_k):\n",
    "                            print(\"Similar questions： {},                score： {}\".format(questionList0[idx], score))\n",
    "\n",
    "                        cost = time2 - time1\n",
    "                        print('It took {} s to look for the answers'.format(cost))\n",
    "                        print('---------------------------------------------------------------------------------------------------')\n",
    "                        print('Is there anything else I can help?')# chats for apple\n",
    "                    elif company=='1':\n",
    "                        question_k = ss1.similarity_v(question, 5)\n",
    "                        time2 = time.time()\n",
    "                        for i in range(5):\n",
    "                            if question_k[1][i]>=0.5:\n",
    "                                print('Thanks for asking, here is the',i+1,'most likely answer from AppleSupport')\n",
    "                                print(answerList1[question_k[0][i]])\n",
    "                                while True:\n",
    "                                    solved=input('Is this problem solved? (input y/n)')\n",
    "                                    if solved=='n' or solved=='y':\n",
    "                                        print()\n",
    "                                        break\n",
    "                                    elif solved!='y':\n",
    "                                        input('Please enter y/n')\n",
    "                                        continue\n",
    "                                if solved=='y':\n",
    "                                    print('Thank you for using Auto Customer Service. It\\'s my pleasure to solve your problem.')\n",
    "                                    break\n",
    "\n",
    "                            else:\n",
    "                                if i == 0:\n",
    "                                    print('Unfortunately, I can\\'t find any answer in our database, please contact human services.' )\n",
    "                                else:\n",
    "                                    print('Unfortunately, I can\\'t find more answers in our database, please contact human services if you still have questions.')\n",
    "                                break\n",
    "\n",
    "\n",
    "                        for idx, score in zip(*question_k):\n",
    "                            print(\"Similar questions： {},                score： {}\".format(questionList1[idx], score))\n",
    "\n",
    "                        cost = time2 - time1\n",
    "                        print('It took {} s to look for the answers'.format(cost))\n",
    "                        print('---------------------------------------------------------------------------------------------------')\n",
    "                        print('Is there anything else I can help?')\n",
    "\n",
    "                    # chats for Uber\n",
    "                    else:\n",
    "                        question_k = ss2.similarity_v(question, 5)\n",
    "                        time2 = time.time()\n",
    "                        for i in range(5):\n",
    "                            if question_k[1][i]>=0.5:\n",
    "                                print('Thanks for asking, here is the',i+1,'most likely answer(s) from Uber_Support')\n",
    "                                print(answerList2[question_k[0][i]])\n",
    "                                while True:\n",
    "                                    solved=input('Is this problem solved? (input y/n)')\n",
    "                                    if solved=='n' or solved=='y':\n",
    "                                        print()\n",
    "                                        break\n",
    "                                    elif solved!='y':\n",
    "                                        input('Please enter y/n')\n",
    "                                        continue\n",
    "                                if solved=='y':\n",
    "                                    print('Thank you for using Auto Customer Service. It\\'s my pleasure to solve your problem.')\n",
    "                                    break\n",
    "\n",
    "                            else:\n",
    "                                if i == 0:\n",
    "                                    print('Unfortunately, I can\\'t find any answer in our database, please contact human services.' )\n",
    "                                else:\n",
    "                                    print('Unfortunately, I can\\'t find more answers in our database, please contact human services if you still have questions.')\n",
    "                                break\n",
    "\n",
    "                        for idx, score in zip(*question_k):\n",
    "                            print(\"Similar questions： {},                score： {}\".format(questionList2[idx], score))\n",
    "\n",
    "                        cost = time2 - time1\n",
    "                        print('It took {} s to look for the answers'.format(cost))\n",
    "                        print('---------------------------------------------------------------------------------------------------')\n",
    "                        print('Is there anything else I can help?')\n",
    "                print('Thank you for asking. Would you like to ask questions about other companies?')\n",
    "                \n",
    "                    \n",
    "            elif company=='q':\n",
    "                print('Thank you. Say safe and have a good one!')\n",
    "                break\n",
    "            else:\n",
    "                print('Please input 0, 1, 2 or q')\n",
    "            \n",
    "        break\n",
    "            \n",
    "            \n",
    "        \n",
    "    elif way == 'tfidf':\n",
    "        print('Please wait for system to set up')\n",
    "        time1=time.time()\n",
    "        seg0 = Seg()\n",
    "        List_kw0, questionList0, answerList0 = read_corpus(dataset[0],seg0)\n",
    "        ss0 = SentenceSimilarity(seg0,clist[0])\n",
    "        ss0.set_sentences(questionList0)\n",
    "        #ss0.w2vModel()\n",
    "        ss0.TfidfModel() \n",
    "        #     ss.LsiModel()\n",
    "        #     ss.LdaModel()        \n",
    "        seg1 = Seg()\n",
    "        List_kw1, questionList1, answerList1 = read_corpus(dataset[1],seg1)\n",
    "        ss1 = SentenceSimilarity(seg1,clist[1])\n",
    "        ss1.set_sentences(questionList1)\n",
    "#         ss1.w2vModel()\n",
    "        ss1.TfidfModel() \n",
    "        seg2 = Seg()\n",
    "        List_kw2, questionList2, answerList2 = read_corpus(dataset[2],seg2)\n",
    "        ss2 = SentenceSimilarity(seg2,clist[2])\n",
    "        ss2.set_sentences(questionList2)\n",
    "#         ss2.w2vModel\n",
    "        ss2.TfidfModel() \n",
    "        time2=time.time()\n",
    "        print('Finished! Time cost for setting up: {} s'.format(time2-time1))\n",
    "        print('---------------------------------------------------------------------------------------------------')\n",
    "        break\n",
    "        \n",
    "    elif way == 'lsi':\n",
    "        print('Please wait for system to set up')\n",
    "        time1=time.time()\n",
    "        seg0 = Seg()\n",
    "        List_kw0, questionList0, answerList0 = read_corpus(dataset[0],seg0)\n",
    "        ss0 = SentenceSimilarity(seg0,clist[0])\n",
    "        ss0.set_sentences(questionList0)\n",
    "        #ss0.w2vModel()\n",
    "#         ss0.TfidfModel() \n",
    "        ss0.LsiModel()\n",
    "        #     ss.LdaModel()        \n",
    "        seg1 = Seg()\n",
    "        List_kw1, questionList1, answerList1 = read_corpus(dataset[1],seg1)\n",
    "        ss1 = SentenceSimilarity(seg1,clist[1])\n",
    "        ss1.set_sentences(questionList1)\n",
    "#         ss1.w2vModel()\n",
    "        ss1.LsiModel() \n",
    "        seg2 = Seg()\n",
    "        List_kw2, questionList2, answerList2 = read_corpus(dataset[2],seg2)\n",
    "        ss2 = SentenceSimilarity(seg2,clist[2])\n",
    "        ss2.set_sentences(questionList2)\n",
    "#         ss2.w2vModel\n",
    "        ss2.LsiModel() \n",
    "        time2=time.time()\n",
    "        print('Finished! Time cost for setting up: {} s'.format(time2-time1))\n",
    "        print('---------------------------------------------------------------------------------------------------')\n",
    "        break\n",
    "        \n",
    "    elif way == 'lda':\n",
    "        print('Please wait for system to set up')\n",
    "        time1=time.time()\n",
    "        seg0 = Seg()\n",
    "        List_kw0, questionList0, answerList0 = read_corpus(dataset[0],seg0)\n",
    "        ss0 = SentenceSimilarity(seg0,clist[0])\n",
    "        ss0.set_sentences(questionList0)\n",
    "        #ss0.w2vModel()\n",
    "#         ss0.TfidfModel() \n",
    "        #     ss.LsiModel()\n",
    "        ss0.LdaModel()        \n",
    "        seg1 = Seg()\n",
    "        List_kw1, questionList1, answerList1 = read_corpus(dataset[1],seg1)\n",
    "        ss1 = SentenceSimilarity(seg1,clist[1])\n",
    "        ss1.set_sentences(questionList1)\n",
    "#         ss1.w2vModel()\n",
    "        ss1.LdaModel() \n",
    "        seg2 = Seg()\n",
    "        List_kw2, questionList2, answerList2 = read_corpus(dataset[2],seg2)\n",
    "        ss2 = SentenceSimilarity(seg2,clist[2])\n",
    "        ss2.set_sentences(questionList2)\n",
    "#         ss2.w2vModel\n",
    "        ss2.LdaModel() \n",
    "        time2=time.time()\n",
    "        print('Finished! Time cost for setting up: {} s'.format(time2-time1))\n",
    "        print('---------------------------------------------------------------------------------------------------')\n",
    "        break\n",
    "    else:\n",
    "        print('Please input right')\n",
    "        continue\n",
    "        \n",
    "if w2v==False:\n",
    "    print('Hey there! This is Auto Customer Service. First please choose the company:')\n",
    "    while True:\n",
    "        company=input('0 for Amazon, 1 for Apple, 2 for Uber: ')\n",
    "        if company in ['0','1','2']:\n",
    "            while True:        \n",
    "                question = input(\"Please type your question here ('q' to quit): \")\n",
    "                if question == 'q':\n",
    "                    break\n",
    "                time1 = time.time()\n",
    "                if company=='0':           \n",
    "                    question_k = ss0.similarity_k(question, 5)\n",
    "                    time2 = time.time()\n",
    "                    for i in range(5):\n",
    "                        if question_k[1][i]>=0.5:\n",
    "                            print('Thanks for asking, here is the',i+1,'most likely answer(s) from AmazonHelp')\n",
    "                            print(answerList0[question_k[0][i]])\n",
    "                            while True:\n",
    "                                solved=input('Is this problem solved? (input y/n)')\n",
    "                                if solved=='n' or solved=='y':\n",
    "                                    print()\n",
    "                                    break\n",
    "                                elif solved!='y':\n",
    "                                    input('Please enter y/n')\n",
    "                                    continue\n",
    "                            if solved=='y':\n",
    "                                print('Thank you for using Auto Customer Service. It\\'s my pleasure to solve your problem.')\n",
    "                                break                    \n",
    "                        else:\n",
    "                            if i == 0:\n",
    "                                print('Unfortunately, I can\\'t find any answer in our database, please contact human services.' )\n",
    "                            else:\n",
    "                                print('Unfortunately, I can\\'t find more answers in our database, please contact human services if you still have questions.')\n",
    "                            break\n",
    "\n",
    "\n",
    "                    for idx, score in zip(*question_k):\n",
    "                        print(\"Similar questions： {},                score： {}\".format(questionList0[idx], score))\n",
    "\n",
    "                    cost = time2 - time1\n",
    "                    print('It took {} s to look for the answers'.format(cost))\n",
    "                    print('---------------------------------------------------------------------------------------------------')\n",
    "                    print('What else can I help')\n",
    "                elif company=='1':\n",
    "                    question_k = ss1.similarity_k(question, 5)\n",
    "                    time2 = time.time()\n",
    "                    for i in range(5):\n",
    "                        if question_k[1][i]>=0.5:\n",
    "                            print('Thanks for asking, here is the',i+1,'most likely answer(s) from AppleSupport')\n",
    "                            print(answerList1[question_k[0][i]])\n",
    "                            while True:\n",
    "                                solved=input('Is this problem solved? (input y/n)')\n",
    "                                if solved=='n' or solved=='y':\n",
    "                                    print()\n",
    "                                    break\n",
    "                                elif solved!='y':\n",
    "                                    input('Please enter y/n')\n",
    "                                    continue\n",
    "                            if solved=='y':\n",
    "                                print('Thank you for using Auto Customer Service. It\\'s my pleasure to solve your problem.')\n",
    "                                break\n",
    "\n",
    "                        else:\n",
    "                            if i == 0:\n",
    "                                print('Unfortunately, I can\\'t find any answer in our database, please contact human services.' )\n",
    "                            else:\n",
    "                                print('Unfortunately, I can\\'t find more answers in our database, please contact human services if you still have questions.')\n",
    "                            break\n",
    "\n",
    "\n",
    "                    for idx, score in zip(*question_k):\n",
    "                        print(\"Similar questions： {},                score： {}\".format(questionList1[idx], score))\n",
    "\n",
    "                    cost = time2 - time1\n",
    "                    print('It took {} s to look for the answers'.format(cost))\n",
    "                    print('---------------------------------------------------------------------------------------------------')\n",
    "                    print('Is there anything else I can help?')\n",
    "                else:\n",
    "                    question_k = ss2.similarity_k(question, 5)\n",
    "                    time2 = time.time()\n",
    "                    for i in range(5):\n",
    "                        if question_k[1][i]>=0.5:\n",
    "                            print('Thanks for asking, here is the',i+1,'most likely answer(s) from Uber_Support')\n",
    "                            print(answerList2[question_k[0][i]])\n",
    "                            while True:\n",
    "                                solved=input('Is this problem solved? (input y/n)')\n",
    "                                if solved=='n' or solved=='y':\n",
    "                                    print()\n",
    "                                    break\n",
    "                                elif solved!='y':\n",
    "                                    input('Please enter y/n')\n",
    "                                    continue\n",
    "                            if solved=='y':\n",
    "                                print('Thank you for using Auto Customer Service. It\\'s my pleasure to solve your problem.')\n",
    "                                break\n",
    "\n",
    "                        else:\n",
    "                            if i == 0:\n",
    "                                print('Unfortunately, I can\\'t find any answer in the systen, please contact human services.' )\n",
    "                            else:\n",
    "                                print('Unfortunately, I can\\'t find more answers in the systen, please contact human services if you still have questions.')\n",
    "                            break\n",
    "\n",
    "\n",
    "                    for idx, score in zip(*question_k):\n",
    "                        print(\"Similar questions： {},                score： {}\".format(questionList2[idx], score))\n",
    "\n",
    "                    cost = time2 - time1\n",
    "                    print('It took {} s to look for the answers?'.format(cost))\n",
    "                    print('---------------------------------------------------------------------------------------------------')\n",
    "                    print('Is there anything else I can help')\n",
    "            \n",
    "            print('Thank you for asking. Do you want to ask questions about other companies?')\n",
    "                \n",
    "                    \n",
    "        elif company=='q':\n",
    "            print('Thank you. Stay safe and have a good one!')\n",
    "            break\n",
    "        else:\n",
    "            print('Please enter 0, 1, 2 or q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I selected free two day delivery but the package arrived late"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling using LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[        tweet_id_x   author_id  inbound                      created_at  \\\n",
       " 2              275  AmazonHelp    False  Wed Nov 22 10:06:26 +0000 2017   \n",
       " 3              324  AmazonHelp    False  Wed Nov 22 09:06:00 +0000 2017   \n",
       " 6              620  AmazonHelp    False  Tue Oct 31 22:28:34 +0000 2017   \n",
       " 8              625  AmazonHelp    False  Tue Oct 31 22:34:32 +0000 2017   \n",
       " 10             629  AmazonHelp    False  Wed Nov 01 12:53:34 +0000 2017   \n",
       " ...            ...         ...      ...                             ...   \n",
       " 168818     2987819  AmazonHelp    False  Wed Nov 22 06:19:27 +0000 2017   \n",
       " 168819     2987821  AmazonHelp    False  Wed Nov 22 06:17:26 +0000 2017   \n",
       " 168820     2987900  AmazonHelp    False  Wed Nov 22 07:09:54 +0000 2017   \n",
       " 168821     2987902  AmazonHelp    False  Wed Nov 22 07:09:53 +0000 2017   \n",
       " 168822     2987938  AmazonHelp    False  Wed Nov 22 07:49:52 +0000 2017   \n",
       " \n",
       "                                                    text_x response_tweet_id  \\\n",
       " 2          恐れ入ります。至らない点も多々あるかとは存じますが、今後ともどうぞよろしくお願いします。ET               NaN   \n",
       " 3       ご不便をおかけしております。アプリをご利用でしょうか。強制停止&gt;端末の再起動にて改善す...               NaN   \n",
       " 6       I am unable to affect your account via Twitter...               NaN   \n",
       " 8            Wir haben zu danken. Schönen Abend noch. ^JS               NaN   \n",
       " 10                          Thanks for your patience. ^KM               NaN   \n",
       " ...                                                   ...               ...   \n",
       " 168818  ご心配をおかけしております。ご案内しているお届け予定日を経過しても未着の場合はカスタマーサー...               NaN   \n",
       " 168819  該当のメッセージは、https://t.co/st4oU5QbhPからお送りしたものではござ...               NaN   \n",
       " 168820  ご承知のとおり、残念ながら悪質な詐欺が増加しているようですのでお気を付けください。\\nhtt...               NaN   \n",
       " 168821  ¡Hola Crispín! Lamento mucho la confusión caus...               NaN   \n",
       " 168822  当サイトからそのようなメールをお送りすることはございません。当サイトの名をかたるフィッシング...               NaN   \n",
       " \n",
       "         in_response_to_tweet_id  tweet_id_y  \\\n",
       " 2                         274.0         274   \n",
       " 3                         325.0         325   \n",
       " 6                         621.0         621   \n",
       " 8                         623.0         623   \n",
       " 10                        627.0         627   \n",
       " ...                         ...         ...   \n",
       " 168818                2987820.0     2987820   \n",
       " 168819                2987822.0     2987822   \n",
       " 168820                2987901.0     2987901   \n",
       " 168821                2987903.0     2987903   \n",
       " 168822                2987939.0     2987939   \n",
       " \n",
       "                                                    text_y  \n",
       " 2                           @AmazonHelp こちらこそありがとうございました。  \n",
       " 3                                amazonプライムビデオ、再生エラーが多いです  \n",
       " 6       @115823 I want my amazon payments account CLOS...  \n",
       " 8                    @AmazonHelp Okay, danke für die Info  \n",
       " 10      @AmazonHelp @115826 Yeah this is crazy we’re l...  \n",
       " ...                                                   ...  \n",
       " 168818  Amazonで注文したDVDがまだ届かない･･･\\n昨日まで到着予定なんだけど問い合わせする...  \n",
       " 168819  たいへん！！Amazonでピンク動画見たら請求来た！！私の消息途絶えたらAmazonに社会か...  \n",
       " 168820  架空請求きたよww\\n\\nしかとショートメールでAmazon相談係。 https://t.c...  \n",
       " 168821  Señores de @116928 estoy confuso sobre el públ...  \n",
       " 168822  いきなり来たんだけど\\nなんですかこれ！！？\\n\\n@120465 https://t.co...  \n",
       " \n",
       " [84566 rows x 9 columns]]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon = []\n",
    "amazon.append(pre(df,'AmazonHelp'))\n",
    "amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = amazon[-1]['text_y'].to_list()\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove '\\r' and punctuations \n",
    "new_text = []\n",
    "for tweet in q: \n",
    "    for i in tweet:\n",
    "        if i in string.punctuation or i == '@':\n",
    "            tweet = tweet.replace(i,'') #replace punctuation with nothing\n",
    "        if i == '\\r':\n",
    "            tweet = tweet.replace(i,' ') #replace \\r with space\n",
    "    new_text.append(tweet) \n",
    "new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stop words, to lowercase and tokenize\n",
    "mystopwords = stopwords.words()\n",
    "tokens_list = [[word for word in tweet.lower().split(' ') if word not in mystopwords and word.isalpha() and word != 'amazon' and word != 'amazonhelp']\n",
    "         for tweet in new_text]\n",
    "tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove words that appear only once\n",
    "frequency = defaultdict(int)\n",
    "\n",
    "for tokens in tokens_list:\n",
    "    for token in tokens:\n",
    "        frequency[token] += 1      \n",
    "tokens_list = [[token for token in tokens if frequency[token]>1]\n",
    "              for tokens in tokens_list]\n",
    "tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Term Document Matrix\n",
    "# generate token dictionary class\n",
    "dictionary = corpora.Dictionary(tokens_list) \n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a unique token list \n",
    "sort_token = sorted(dictionary.items(),key=lambda k:k[0], reverse = False)\n",
    "unique_token = [token for (ID,token) in sort_token]\n",
    "\n",
    "# build a corpus\n",
    "corpus = [dictionary.doc2bow(tokens) for tokens in tokens_list]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a Term Document Matrix\n",
    "matrix = gensim.matutils.corpus2dense(corpus,num_terms=len(dictionary),dtype = 'int')\n",
    "matrix = matrix.T \n",
    "#transpose the matrix \n",
    "\n",
    "#convert the numpy matrix into pandas dataframe\n",
    "matrix_df = pd.DataFrame(matrix, columns=unique_token)\n",
    "matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit to LDA model\n",
    "lda = models.LdaModel(corpus, id2word=dictionary, num_topics=10) \n",
    "\n",
    "#Topic matrix (V matrix)\n",
    "lda.print_topics(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate U Matrix for LDA model\n",
    "corpus_lda = lda[corpus] \n",
    "#transform lda model\n",
    "\n",
    "#convert corpus_lda to numpy matrix\n",
    "U_matrix_lda = gensim.matutils.corpus2dense(corpus_lda,num_terms=10).T\n",
    "\n",
    "#write U_matrix into pandas dataframe and output\n",
    "U_matrix_lda_df = pd.DataFrame(U_matrix_lda)\n",
    "U_matrix_lda_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (matrix_df.shape)\n",
    "print (U_matrix_lda_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.gensim.prepare(lda, corpus, dictionary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
